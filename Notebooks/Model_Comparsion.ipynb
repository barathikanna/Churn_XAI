{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c126bd-8532-4b90-9cf0-aed7027242b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Model Comparison (Structured only data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce2ef20-f417-489f-aa90-93f5269093d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, precision_score, recall_score, f1_score, accuracy_score\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load data\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"/content/drive/MyDrive/Project/Dataset/causal_discount_churn_DAG_clean.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please update the file path.\")\n",
    "    # Creating a dummy dataframe for demonstration purposes if the file is not found\n",
    "    data = {\n",
    "        'age': np.random.randint(18, 70, 1000),\n",
    "        'gender': np.random.choice(['Male', 'Female'], 1000),\n",
    "        'tenure_months': np.random.randint(1, 60, 1000),\n",
    "        'hour_spend_on_app': np.random.uniform(0.5, 10, 1000),\n",
    "        'visits_last_month': np.random.randint(0, 30, 1000),\n",
    "        'avg_purchase_value': np.random.uniform(10, 200, 1000),\n",
    "        'number_devices': np.random.randint(1, 5, 1000),\n",
    "        'preferred_payment': np.random.choice(['Credit Card', 'Debit Card', 'PayPal'], 1000),\n",
    "        'preferred_category': np.random.choice(['Electronics', 'Clothing', 'Groceries'], 1000),\n",
    "        'delivery_distance_km': np.random.uniform(1, 50, 1000),\n",
    "        'satisfaction_score': np.random.randint(1, 5, 1000),\n",
    "        'loyalty_score': np.random.randint(1, 10, 1000),\n",
    "        'discount_offer': np.random.choice(['Yes', 'No'], 1000),\n",
    "        'churned': np.random.randint(0, 2, 1000)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "features = [\n",
    "    \"age\",\n",
    "    \"gender\",\n",
    "    \"tenure_months\",\n",
    "    \"hour_spend_on_app\",\n",
    "    \"visits_last_month\",\n",
    "    \"avg_purchase_value\",\n",
    "    \"number_devices\",\n",
    "    \"preferred_payment\",\n",
    "    \"preferred_category\",\n",
    "    \"delivery_distance_km\",\n",
    "    \"satisfaction_score\",\n",
    "    \"loyalty_score\",\n",
    "    \"discount_offer\"\n",
    "]\n",
    "target = \"churned\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "numeric_features = [\n",
    "    \"age\",\n",
    "    \"tenure_months\",\n",
    "    \"hour_spend_on_app\",\n",
    "    \"visits_last_month\",\n",
    "    \"avg_purchase_value\",\n",
    "    \"number_devices\",\n",
    "    \"delivery_distance_km\",\n",
    "    \"satisfaction_score\",\n",
    "    \"loyalty_score\"\n",
    "]\n",
    "categorical_features = [\n",
    "    \"gender\",\n",
    "    \"preferred_payment\",\n",
    "    \"preferred_category\",\n",
    "    \"discount_offer\"\n",
    "]\n",
    "\n",
    "# Preprocessor: scale numeric, one-hot categorical\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "# evaluation function \n",
    "\n",
    "def evaluate_model(name, y_test, y_proba):\n",
    "    \"\"\"\n",
    "    Evaluates the model, calculates key metrics and their standard errors,\n",
    "    and plots a confusion matrix.\n",
    "    \"\"\"\n",
    "    # Find the best threshold to maximize F1-score\n",
    "    prec, rec, thr = precision_recall_curve(y_test, y_proba)\n",
    "    f1_scores = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_thresh = thr[best_idx]\n",
    "    y_pred = (y_proba >= best_thresh).astype(int)\n",
    "\n",
    "    print(f\"\\n{name} Best threshold: {best_thresh:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    # --- Calculate Metrics ---\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{name} ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    #Standard Error for Metrics \n",
    "\n",
    "    n = len(y_test)\n",
    "    accuracy_err = np.sqrt(accuracy * (1 - accuracy) / n)\n",
    "    precision_err = np.sqrt(precision * (1 - precision) / n)\n",
    "    recall_err = np.sqrt(recall * (1 - recall) / n)\n",
    "    \n",
    "    #Confusion Matrix \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Not Churned', 'Churned'],\n",
    "                yticklabels=['Not Churned', 'Churned'])\n",
    "    plt.title(f'{name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    #Metrics and their Errors\n",
    "    metrics = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Accuracy_err\": accuracy_err,\n",
    "        \"ROC AUC_err\": 0,  # Standard error for ROC AUC is complex, so we'll omit it for the plot\n",
    "        \"F1 Score_err\": 0, # Standard error for F1 is complex, so we'll omit it for the plot\n",
    "        \"Precision_err\": precision_err,\n",
    "        \"Recall_err\": recall_err,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "# 1. XGBoost pipeline & tuning\n",
    "pipeline_xgb = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        use_label_encoder=False,\n",
    "        seed=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0,\n",
    "    ))\n",
    "])\n",
    "param_dist_xgb = {\n",
    "    'classifier__n_estimators': [100, 200], 'classifier__max_depth': [3, 4],\n",
    "    'classifier__learning_rate': [0.01, 0.05], 'classifier__subsample': [0.7, 0.8],\n",
    "    'classifier__colsample_bytree': [0.7, 0.8], 'classifier__min_child_weight': [1, 3],\n",
    "    'classifier__gamma': [0, 0.1], 'classifier__scale_pos_weight': [1],\n",
    "}\n",
    "search_xgb = RandomizedSearchCV(\n",
    "    pipeline_xgb, param_distributions=param_dist_xgb, n_iter=15, scoring='roc_auc',\n",
    "    cv=3, verbose=0, random_state=42, n_jobs=-1, refit=True\n",
    ")\n",
    "search_xgb.fit(X_train, y_train)\n",
    "y_proba_xgb = search_xgb.predict_proba(X_test)[:, 1]\n",
    "metrics_list.append(evaluate_model(\"XGBoost\", y_test, y_proba_xgb))\n",
    "\n",
    "\n",
    "# 2. LightGBM pipeline & tuning\n",
    "pipeline_lgb = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', lgb.LGBMClassifier(\n",
    "        objective='binary', boosting_type='gbdt', metric='auc',\n",
    "        random_state=42, n_jobs=-1,\n",
    "    ))\n",
    "])\n",
    "param_dist_lgb = {\n",
    "    'classifier__n_estimators': [100, 200], 'classifier__max_depth': [4, 5, -1],\n",
    "    'classifier__learning_rate': [0.01, 0.05], 'classifier__num_leaves': [31, 50],\n",
    "    'classifier__subsample': [0.7, 0.8], 'classifier__colsample_bytree': [0.7, 0.8],\n",
    "    'classifier__min_child_samples': [10, 20],\n",
    "}\n",
    "search_lgb = RandomizedSearchCV(\n",
    "    pipeline_lgb, param_distributions=param_dist_lgb, n_iter=15, scoring='roc_auc',\n",
    "    cv=3, verbose=0, random_state=42, n_jobs=-1, refit=True\n",
    ")\n",
    "search_lgb.fit(X_train, y_train)\n",
    "y_proba_lgb = search_lgb.predict_proba(X_test)[:, 1]\n",
    "metrics_list.append(evaluate_model(\"LightGBM\", y_test, y_proba_lgb))\n",
    "\n",
    "\n",
    "# 3. Random Forest pipeline & tuning\n",
    "pipeline_rf = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        random_state=42, n_jobs=-1, class_weight='balanced'\n",
    "    ))\n",
    "])\n",
    "param_dist_rf = {\n",
    "    'classifier__n_estimators': [100, 200], 'classifier__max_depth': [None, 10],\n",
    "    'classifier__min_samples_split': [2, 5], 'classifier__min_samples_leaf': [1, 2],\n",
    "}\n",
    "search_rf = RandomizedSearchCV(\n",
    "    pipeline_rf, param_distributions=param_dist_rf, n_iter=15, scoring='roc_auc',\n",
    "    cv=3, verbose=0, random_state=42, n_jobs=-1, refit=True\n",
    ")\n",
    "search_rf.fit(X_train, y_train)\n",
    "y_proba_rf = search_rf.predict_proba(X_test)[:, 1]\n",
    "metrics_list.append(evaluate_model(\"Random Forest\", y_test, y_proba_rf))\n",
    "\n",
    "\n",
    "# 4. Logistic Regression\n",
    "pipeline_lr = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', LogisticRegression(solver='liblinear', random_state=42))\n",
    "])\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "y_proba_lr = pipeline_lr.predict_proba(X_test)[:, 1]\n",
    "metrics_list.append(evaluate_model(\"Logistic Regression\", y_test, y_proba_lr))\n",
    "\n",
    "\n",
    "# 5. Simple ANN\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_proc, y_train)\n",
    "input_dim = X_train_res.shape[1]\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train_res, y_train_res, validation_split=0.2, epochs=100,\n",
    "    batch_size=64, callbacks=[early_stop], verbose=0\n",
    ")\n",
    "y_proba_ann = model.predict(X_test_proc).ravel()\n",
    "metrics_list.append(evaluate_model(\"Simple ANN\", y_test, y_proba_ann))\n",
    "\n",
    "\n",
    "#Bar plot for all models\n",
    "df_metrics = pd.DataFrame(metrics_list)\n",
    "\n",
    "metrics_to_plot = [\"Accuracy\", \"ROC AUC\", \"F1 Score\", \"Precision\", \"Recall\"]\n",
    "models = df_metrics['Model'].unique()\n",
    "n_models = len(models)\n",
    "n_metrics = len(metrics_to_plot)\n",
    "\n",
    "# Setup for the plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "bar_width = 0.15\n",
    "index = np.arange(n_metrics)\n",
    "\n",
    "# Plot bars for each model\n",
    "for i, model_name in enumerate(models):\n",
    "    model_data = df_metrics[df_metrics['Model'] == model_name]\n",
    "    \n",
    "    # Get metric values and errors\n",
    "    values = [model_data[metric].values[0] for metric in metrics_to_plot]\n",
    "    errors = [model_data[metric + '_err'].values[0] for metric in metrics_to_plot]\n",
    "    \n",
    "    # Position for the bars\n",
    "    bar_position = index - (bar_width * (n_models - 1) / 2) + (i * bar_width)\n",
    "    \n",
    "    # Create bars with error bars\n",
    "    bars = ax.bar(bar_position, values, bar_width, label=model_name, yerr=errors, capsize=4)\n",
    "    \n",
    "    # Add exact value labels on top of each bar\n",
    "    ax.bar_label(bars, fmt='%.3f', padding=3, fontsize=9)\n",
    "\n",
    "#Formatting the plot\n",
    "ax.set_xlabel('Metric', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Model Performance Comparison (Structured only)', fontweight='bold', fontsize=16)\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(metrics_to_plot, fontsize=11)\n",
    "ax.legend(title='Models', bbox_to_anchor=(1.04, 1), loc='upper left')\n",
    "ax.set_ylim(0, 1) # Set y-limit to give space for labels\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965dd3f-df07-44f6-a887-1655a39851ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression vs XGBoost (Structured only data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae000b4f-627b-44b8-aaaa-23278621024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1. Load the dataset\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"/content/drive/MyDrive/Project/Dataset/causal_discount_churn_DAG_clean.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found. Please update the file path.\")\n",
    "    # Creating a dummy dataframe for demonstration purposes if the file is not found\n",
    "    data = {\n",
    "        'age': np.random.randint(18, 70, 1000),\n",
    "        'gender': np.random.choice(['Male', 'Female'], 1000),\n",
    "        'tenure_months': np.random.randint(1, 60, 1000),\n",
    "        'hour_spend_on_app': np.random.uniform(0.5, 10, 1000),\n",
    "        'visits_last_month': np.random.randint(0, 30, 1000),\n",
    "        'avg_purchase_value': np.random.uniform(10, 200, 1000),\n",
    "        'number_devices': np.random.randint(1, 5, 1000),\n",
    "        'preferred_payment': np.random.choice(['Credit Card', 'Debit Card', 'PayPal'], 1000),\n",
    "        'preferred_category': np.random.choice(['Electronics', 'Clothing', 'Groceries'], 1000),\n",
    "        'delivery_distance_km': np.random.uniform(1, 50, 1000),\n",
    "        'satisfaction_score': np.random.randint(1, 5, 1000),\n",
    "        'loyalty_score': np.random.randint(1, 10, 1000),\n",
    "        'discount_offer': np.random.randint(0, 2, 1000),\n",
    "        'churned': np.random.randint(0, 2, 1000)\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# 2. Define features and target\n",
    "features = ['age', 'gender', 'tenure_months', 'hour_spend_on_app', 'visits_last_month', 'avg_purchase_value', 'number_devices', 'preferred_payment', 'preferred_category', 'delivery_distance_km', 'satisfaction_score', 'loyalty_score', 'discount_offer']\n",
    "target = \"churned\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# 3. train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Preprocessing pipeline\n",
    "numeric_features = ['age', 'tenure_months', 'hour_spend_on_app', 'visits_last_month', 'avg_purchase_value', 'number_devices', 'delivery_distance_km', 'satisfaction_score', 'loyalty_score', 'discount_offer']\n",
    "categorical_features = ['gender', 'preferred_payment', 'preferred_category']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown='ignore'), categorical_features)\n",
    "])\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "y_pred_lr = lr_pipeline.predict(X_test)\n",
    "y_proba_lr = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# XGBoost\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "neg, pos = (y == 0).sum(), (y == 1).sum()\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_transformed, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_transformed, label=y_test)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 4,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=200,\n",
    "    early_stopping_rounds=10,\n",
    "    evals=[(dtest, \"eval\")],\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "y_proba_xgb = bst.predict(dtest)\n",
    "y_pred_xgb = (y_proba_xgb >= 0.5).astype(int)\n",
    "\n",
    "# Evaluation Function with error calculation \n",
    "def evaluate(name, y_true, y_pred, y_proba):\n",
    "    \"\"\"\n",
    "    Calculates key metrics and their standard errors.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate standard error for metrics that are proportions\n",
    "    n = len(y_true)\n",
    "    accuracy_err = np.sqrt(accuracy * (1 - accuracy) / n)\n",
    "    precision_err = np.sqrt(precision * (1 - precision) / n)\n",
    "    recall_err = np.sqrt(recall * (1 - recall) / n)\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1_score(y_true, y_pred),\n",
    "        \"ROC AUC\": roc_auc_score(y_true, y_proba),\n",
    "        \"Accuracy_err\": accuracy_err,\n",
    "        \"Precision_err\": precision_err,\n",
    "        \"Recall_err\": recall_err,\n",
    "        \"F1 Score_err\": 0, # Standard error for F1 is complex, omitting for the plot\n",
    "        \"ROC AUC_err\": 0,  # Standard error for ROC AUC is complex, omitting for the plot\n",
    "    }\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "results.append(evaluate(\"Logistic Regression\", y_test, y_pred_lr, y_proba_lr))\n",
    "results.append(evaluate(\"XGBoost\", y_test, y_pred_xgb, y_proba_xgb))\n",
    "\n",
    "# bar plot for all models \n",
    "df_metrics = pd.DataFrame(results)\n",
    "\n",
    "metrics_to_plot = [\"Accuracy\", \"ROC AUC\", \"F1 Score\", \"Precision\", \"Recall\"]\n",
    "models = df_metrics['Model'].unique()\n",
    "n_models = len(models)\n",
    "n_metrics = len(metrics_to_plot)\n",
    "\n",
    "# Setup for the plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "bar_width = 0.35 # Adjusted for two models\n",
    "index = np.arange(n_metrics)\n",
    "\n",
    "# Plot bars for each model\n",
    "for i, model_name in enumerate(models):\n",
    "    model_data = df_metrics[df_metrics['Model'] == model_name]\n",
    "      \n",
    "    values = [model_data[metric].values[0] for metric in metrics_to_plot]\n",
    "    errors = [model_data[metric + '_err'].values[0] for metric in metrics_to_plot]\n",
    "    \n",
    "    bar_position = index - bar_width/2 + i * bar_width\n",
    "    \n",
    "    bars = ax.bar(bar_position, values, bar_width, label=model_name, yerr=errors, capsize=5)\n",
    "    \n",
    "    ax.bar_label(bars, fmt='%.3f', padding=3, fontsize=10)\n",
    "\n",
    "# Formatting the plot \n",
    "ax.set_xlabel('Metric', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Logistic Regression vs XGBoost Performance (Structured)', fontweight='bold', fontsize=16)\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(metrics_to_plot, fontsize=11)\n",
    "ax.legend(title='Models', bbox_to_anchor=(1.04, 1), loc='upper left')\n",
    "ax.set_ylim(0, 1) # Set y-limit to give space for labels\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
